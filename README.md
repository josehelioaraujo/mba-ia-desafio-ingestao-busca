# Sistema RAG - Chat com Documentos PDF

Sistema de Retrieval-Augmented Generation (RAG) desenvolvido para o Desafio MBA IA, permitindo consultas inteligentes sobre documentos PDF atravÃ©s de interface de chat via linha de comando.

## Funcionamento

O sistema implementa uma arquitetura RAG completa que combina busca vetorial e lexical para responder perguntas sobre conteÃºdo de documentos PDF. O fluxo principal inclui:

1. **IngestÃ£o**: Processamento do PDF em chunks, geraÃ§Ã£o de embeddings e armazenamento no banco vetorial
2. **Busca HÃ­brida**: CombinaÃ§Ã£o de busca vetorial (semÃ¢ntica) e lexical (termos exatos)
3. **Processamento Inteligente**: PrÃ©-processamento especÃ­fico para consultas comparativas
4. **Resposta**: GeraÃ§Ã£o de respostas baseadas exclusivamente no contexto recuperado

### CaracterÃ­sticas Principais

- **MÃºltiplos LLMs**: Suporte a OpenAI (ChatGPT) e Google (Gemini) com fallback automÃ¡tico
- **Busca HÃ­brida**: Vetorial + lexical para maior precisÃ£o
- **OtimizaÃ§Ãµes por Modelo**: Processamento especializado para consultas comparativas no Gemini
- **Interface CLI**: Chat interativo via linha de comando com comandos especiais
- **AderÃªncia ao Contexto**: Sistema rigoroso para evitar alucinaÃ§Ãµes

## Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   document.pdf  â”‚â”€â”€â”€â–¶â”‚   ingest.py      â”‚â”€â”€â”€â–¶â”‚  PostgreSQL +   â”‚
â”‚                 â”‚    â”‚  - PyPDFLoader   â”‚    â”‚   pgVector      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - TextSplitter  â”‚    â”‚                 â”‚
                       â”‚  - Embeddings    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    chat.py      â”‚â”€â”€â”€â–¶â”‚    search.py     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  - Interface    â”‚    â”‚  - Busca HÃ­brida â”‚
â”‚  - Comandos     â”‚    â”‚  - PrÃ©-process   â”‚
â”‚                 â”‚    â”‚  - LLM Handler   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  llm_handler.py  â”‚
                       â”‚  - OpenAI/Gemini â”‚
                       â”‚  - Fallback      â”‚
                       â”‚  - Multi-model   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Estrutura de Arquivos

```
projeto/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chat.py           # Interface principal do chat
â”‚   â”œâ”€â”€ search.py         # LÃ³gica de busca hÃ­brida e prompts
â”‚   â”œâ”€â”€ llm_handler.py    # Gerenciador de mÃºltiplos LLMs
â”‚   â””â”€â”€ ingest.py         # Script de ingestÃ£o do PDF
â”œâ”€â”€ docker-compose.yml    # ConfiguraÃ§Ã£o PostgreSQL + pgVector
â”œâ”€â”€ requirements.txt      # DependÃªncias Python
â”œâ”€â”€ .env.example         # Template de variÃ¡veis de ambiente
â”œâ”€â”€ document.pdf         # Documento para processamento
â””â”€â”€ README.md            # Esta documentaÃ§Ã£o
```

## Bibliotecas e DependÃªncias

### Core Framework
- **LangChain**: Framework principal para RAG e LLMs
- **LangChain Community**: Loaders de documentos (PyPDF)
- **LangChain Text Splitters**: DivisÃ£o inteligente de texto

### Bancos e VetorizaÃ§Ã£o
- **pgVector**: ExtensÃ£o PostgreSQL para busca vetorial
- **psycopg2**: Cliente PostgreSQL para Python
- **LangChain Postgres**: IntegraÃ§Ã£o LangChain + PostgreSQL

### Modelos LLM
- **LangChain OpenAI**: IntegraÃ§Ã£o com ChatGPT e embeddings
- **LangChain Google GenAI**: IntegraÃ§Ã£o com Gemini

### UtilitÃ¡rios
- **python-dotenv**: Gerenciamento de variÃ¡veis de ambiente
- **pypdf**: Processamento de arquivos PDF
- **numpy**: OperaÃ§Ãµes numÃ©ricas para embeddings

## InstruÃ§Ãµes de InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- Docker e Docker Compose
- Git

### 1. Clone o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd projeto-rag
```

### 2. Configure o Ambiente Python

```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
# No Linux/WSL:
source venv/bin/activate
# No Windows:
venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 3. Configure as API Keys

```bash
# Copiar template de configuraÃ§Ã£o
cp .env.example .env

# Editar arquivo .env com suas chaves
nano .env
```

Configure no arquivo `.env`:

```env
# OpenAI Configuration
OPENAI_API_KEY='sk-sua_chave_openai_aqui'
OPENAI_MODEL=gpt-4o-mini

# Google AI Configuration  
GOOGLE_API_KEY='sua_chave_google_aqui'
GOOGLE_MODEL=gemini-2.0-flash-lite

# Default Settings (opcional)
DEFAULT_LLM_MODEL=gemini
DEFAULT_EMBEDDING_MODEL=text-embedding-3-small

# Database (manter como estÃ¡)
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/rag
```

### 4. Inicialize o Banco de Dados

```bash
# Subir PostgreSQL com pgVector
docker compose up -d

# Verificar se estÃ¡ rodando
docker compose ps

# Aguardar inicializaÃ§Ã£o completa
docker compose logs postgres
```

### 5. Execute a IngestÃ£o do PDF

```bash
# Processar o documento PDF
python src/ingest.py
```

**SaÃ­da esperada:**
```
ğŸ“„ Iniciando ingestÃ£o do PDF...
âœ… PDF carregado: X pÃ¡ginas
ğŸ”— Processando texto completo...
âœ… Texto completo: X caracteres
âœ‚ï¸ Dividindo em chunks...
âœ… X chunks criados
ğŸ”— Criando embeddings...
ğŸ’¾ Salvando no banco vetorial PostgreSQL...
ğŸ‰ SUCESSO! PDF ingerido com X chunks
```

### 6. Execute o Chat

```bash
# Iniciar sistema de chat
python src/chat.py
```

## Manual de Uso do Chat

### Comandos Especiais

- `modelo` - Ver modelo LLM atual
- `modelos` - Listar todos os modelos disponÃ­veis
- `trocar` - Trocar modelo interativamente
- `status` - Ver status completo do sistema
- `sair` - Encerrar o chat

### Exemplos de Consultas

**Consultas Comparativas:**
```
Qual a empresa de maior faturamento?
Liste as 3 empresas com maior faturamento
Quais as 5 empresas com menor faturamento?
```

**Consultas EspecÃ­ficas:**
```
Qual o faturamento da SuperTechIABrazil?
Qual o ano de fundaÃ§Ã£o da Alfa Energia S.A.?
Quantas empresas tÃªm 'SustentÃ¡vel' no nome?
```

**Teste de AderÃªncia:**
```
Qual Ã© a capital da FranÃ§a?
Como fazer um bolo de chocolate?
```

## EvidÃªncias de Testes

### Bateria de Testes Realizada

Foram executados testes comparativos entre ChatGPT (gpt-4o-mini) e Google Gemini (2.0-flash-lite):

| Categoria | Teste | ChatGPT | Gemini | Resultado |
|-----------|-------|---------|---------|-----------|
| **Comparativas** | Maior faturamento | âœ… Vanguarda Siderurgia ParticipaÃ§Ãµes | âœ… Vanguarda Siderurgia ParticipaÃ§Ãµes | Ambos corretos |
| | Top 3 faturamento | âœ… Lista completa + valores | âœ… Lista completa | Ambos corretos |
| | 5 menores faturamento | âœ… OrdenaÃ§Ã£o correta | âœ… OrdenaÃ§Ã£o correta | Ambos corretos |
| | Empresa mais recente | âœ… SuperTechIABrazil (2025) | âœ… SuperTechIABrazil | Ambos corretos |
| **EspecÃ­ficas** | Faturamento especÃ­fico | âœ… R$ 10.000.000,00 | âœ… R$ 10.000.000,00 | Ambos corretos |
| | Ano de fundaÃ§Ã£o | âœ… 1972 | âœ… 1972 | Ambos corretos |
| | Contagem empresas | âœ… 18 empresas | âœ… 9 empresas | DiscrepÃ¢ncia minor |
| **AderÃªncia** | Capital FranÃ§a | âœ… Negou responder | âœ… Negou responder | Ambos corretos |
| | Clientes 2024 | âŒ InterpretaÃ§Ã£o incorreta | âœ… Negou responder | Gemini superior |
| | Receita bolo | âœ… Negou responder | âœ… Negou responder | Ambos corretos |

### AnÃ¡lise de Performance

**Pontos Fortes:**
- âœ… **PrecisÃ£o em consultas comparativas**: Ambos os modelos identificam corretamente valores mÃ¡ximos/mÃ­nimos
- âœ… **AderÃªncia ao contexto**: Sistema evita alucinaÃ§Ãµes efetivamente
- âœ… **Consultas especÃ­ficas**: InformaÃ§Ãµes pontuais sÃ£o recuperadas com precisÃ£o
- âœ… **OrdenaÃ§Ã£o matemÃ¡tica**: PrÃ©-processamento garante comparaÃ§Ãµes numÃ©ricas corretas

**DiscrepÃ¢ncias Identificadas:**
- **Contagem de entidades**: VariaÃ§Ã£o entre modelos (18 vs 9 empresas com "SustentÃ¡vel")
- **InterpretaÃ§Ã£o ambÃ­gua**: ChatGPT ocasionalmente interpreta perguntas fora do contexto

### Causas TÃ©cnicas das DiscrepÃ¢ncias

1. **Busca vetorial nÃ£o-determinÃ­stica**: Diferentes embeddings (OpenAI vs Google) recuperam chunks ligeiramente diferentes
2. **LimitaÃ§Ã£o k=30**: Nem todos os dados relevantes sÃ£o sempre recuperados
3. **Busca lexical variÃ¡vel**: Termos podem estar distribuÃ­dos em chunks nÃ£o recuperados
4. **Processamento de contexto**: VariaÃ§Ãµes sutis na interpretaÃ§Ã£o de texto entre modelos

## Melhorias Futuras

### Interface e ExperiÃªncia do UsuÃ¡rio

**Interface Web Moderna:**
- Desenvolver interface web com Streamlit ou FastAPI + React
- Chat em tempo real com histÃ³rico persistente
- Upload de mÃºltiplos PDFs via drag & drop
- VisualizaÃ§Ã£o de chunks recuperados para transparÃªncia
- Indicadores de confianÃ§a das respostas

**Interface Mobile:**
- Aplicativo mobile para consultas via voz
- IntegraÃ§Ã£o com assistentes virtuais (Siri, Google Assistant)
- NotificaÃ§Ãµes push para atualizaÃ§Ãµes de documentos

### Melhorias TÃ©cnicas

**Curto Prazo:**
- Aumentar k para 50-100 chunks para maior cobertura
- Implementar cache Redis para consultas frequentes
- Adicionar suporte a mÃºltiplos formatos (DOCX, TXT, HTML)
- Sistema de logs estruturados para analytics

**MÃ©dio Prazo:**
- **GraphRAG**: Implementar busca baseada em grafos de conhecimento
- **Embeddings fine-tuned**: Treinar embeddings especÃ­ficos para dados empresariais
- **Multi-modal RAG**: Suporte a imagens, tabelas e grÃ¡ficos
- **Agentes especializados**: LLM agents para diferentes tipos de consulta

**Longo Prazo:**
- **RAG AvanÃ§ado**: Multi-hop reasoning e chain-of-thought
- **Base de conhecimento hÃ­brida**: CombinaÃ§Ã£o de dados estruturados e nÃ£o-estruturados
- **Sistema de feedback**: Aprendizado contÃ­nuo baseado em correÃ§Ãµes
- **API empresarial**: Endpoints REST para integraÃ§Ã£o com sistemas externos


---

## Tecnologias Utilizadas

**Backend:**
- Python 3.8+
- LangChain
- PostgreSQL + pgVector
- Docker

**LLMs:**
- OpenAI GPT-4o-mini
- Google Gemini 2.0-flash-lite

**Embeddings:**
- OpenAI text-embedding-3-small
- Google Generative AI Embeddings

---

## ConclusÃ£o

O projeto demonstra uma implementaÃ§Ã£o robusta de RAG que combina as melhores prÃ¡ticas de recuperaÃ§Ã£o de informaÃ§Ã£o com modelos de linguagem modernos. A arquitetura hÃ­brida e as otimizaÃ§Ãµes especÃ­ficas por modelo garantem alta precisÃ£o nas respostas, enquanto mantÃ©m a aderÃªncia rigorosa ao contexto para evitar alucinaÃ§Ãµes.

As evidÃªncias de teste comprovam a eficÃ¡cia do sistema para diferentes tipos de consulta, e o roadmap de melhorias futuras posiciona a soluÃ§Ã£o para evoluÃ§Ã£o contÃ­nua e aplicaÃ§Ã£o em cenÃ¡rios empresariais complexos.